% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluation.R
\name{crossValidateAlgos_par}
\alias{crossValidateAlgos_par}
\title{Evaluates the quality of different algos by parallel cross-validation of their predictions}
\usage{
crossValidateAlgos_par(
  models,
  subgroupQualityFuncs,
  quantile.probs,
  dbY,
  dbTrt,
  dbX,
  numTrials,
  splitFunc,
  splitOpts,
  numCores
)
}
\arguments{
\item{models}{is a vector of model descriptios that contains Train function, Train options, Predict function and the name of the model.
The prototype of the train function is function(Y,Trt,X, opts),
  where Y is the response variable, Trt is the 0-1 treatment variable, X is the covariate matrix, and opts is the options from the corresponding model.
The prototype for the Predict function is function(m,X) where m is a trained model and X the observations for prediction.}

\item{subgroupQualityFuncs}{is a vector of functions that evaluate the quality of a subgroup. The prototype is function(subgroup, Y, Trt), where subgroup is T-F vector defining a subgroup, and Y and Trt are similar as for the functions from trainModelFuncs}

\item{quantile.probs}{is a vector of probabilities for quantile in order to determine subgroups where an effect should be computed}

\item{dbY}{a response variable}

\item{dbTrt}{a treatment 0-1 variable}

\item{dbX}{train covariates}

\item{numTrials}{a number of times a random division in train-holdout subdataset should be taken}

\item{splitFunc}{a function that splits the dataset into training and holdout sets}

\item{splitOpts}{the options that are passed to trainHoldoutSplittingFunc}

\item{numCores}{a number of CPU Cores used in parallel computation}
}
\value{
a list with found subgroups in the holdout set of length holdoutProportion*length(dbY)*numTrials, their sizes, qualities, and qualities of a random subset of similar size for all the algorithms
}
\description{
Evaluates the quality of different algos by parallel cross-validation of their predictions allowing tuning of algos
}
\details{
Takes a set of models and returns the quality of the selected groups by means of subgroupQualityFunc in Cross-Validation
}
\examples{

# Generating dataset
N = 1000
Trt = rbinom(N,1,0.5)
X = data.frame(X1=rbinom(N,1,0.6), X2=rnorm(N), X3=rnorm(N))
Y = as.numeric( ( 2*X$X1 - 1 + X$X2*Trt + rnorm(N) ) > 0 )
# Defining models

#models=list(
list(Name="Weisberg GML", TrainFunc=trainWeisbergGLM, PredictFunc=predictWeisbergGLM, TuneFunc = tuneWeisbergGLM,
TuneOpts=NULL, TrainOpts=list(alpha = 0, lambda = 0.15), PredictOpts=list(fraction=0.7))
#list(Name="Weisberg SVM", TrainFunc="trainWeisbergSVM", PredictFunc="predictSVM", TrainOpts=NULL),
#list(Name="Weisberg RF", TrainFunc=trainWeisbergRF, PredictFunc=predictWeisbergRF, TuneFunc=tuneWeisbergRF, TuneOpts=NULL, TrainOpts=list(mtry = 2, ntree = 5, nodesize = 200))
#list(Name="Weisberg XGb", TrainFunc=trainWeisbergXGb, PredictFunc=predictXSb, TuneFunc=trainWXG_tune, TuneOpts=list(nrounds = c(10, 15, 20), eta = c(0.3, 0.35), subsample = c(0.5, 0.6, 0.8), depth = c(2, 4, 5)), TrainOpts=NULL)
#list(Name="2 GML", TrainFunc=train2MGML, PredictFunc=predict2MGML, TuneFunc = trainWlogit_tune, TuneOpts=list(alpha = c(0, 0.1, 0.5), lambda = c(0.05, 0.15, 0.2)), TrainOpts=NULL)
#list(Name="2 SVM", TrainFunc=train2MSVM, PredictFunc=predict2MSVM, TrainOpts=NULL),
#list(Name="2 RF", TrainFunc=train2MRF, PredictFunc=predict2MRF, TrainOpts=list(ntree = 75)),
#list(Name="2 XGb", TrainFunc=train2MXGb, PredictFunc=predict2MXGb, TrainOpts=list(nrounds = 250)),
#list(Name="RF UPLIFT", TrainFunc=trainUpliftModelRF, PredictFunc=predictUpliftModelRF, TrainOpts=NULL)
)


#models=list(
  #list(Name="RandomForest", TrainFunc=trainModelRandomForest, PredictFunc=predictByModelRandomForest, TrainOpts=NULL, TuneOpts=NULL),
  #list(Name="LMbyTian", TrainFunc=trainModelModLM, PredictFunc=predictByModelModLM, TrainOpts=NULL, TuneOpts=NULL),
  #list(Name="ALL", TrainFunc=function(a,b,c,d){NULL}, PredictFunc=function(m,X){rep(1,nrow(X))},TrainOpts=NULL, TuneOpts=NULL)
#)
# Evaluating algos
res = crossValidateAlgos_par(
    models, # The description of the evaluated models
    c(subgroupAverageTreatmentEffect,subgroupTotalTreatmentEffect), # The set of functions that compute the quality of a subgroup
    seq(0, by = 0.2, to = 1), # Groups of 20\%
    Y, Trt, X,
    numTrials = 17,
    randomSplit_equal, list(TestProportion = 0.5),
    numCores = 20
    )
aggregate(cbind(V1, V2) ~ Model, res$Qualities, FUN=mean)

}
